---
title:  "1.4 Word Embedding"
excerpt: 

categories:
  - Matlab
tags:
  - [Text Analytics Toolbox]

toc: true
toc_sticky: true
 
date: 2022-04-05
last_modified_at: 2022-04-05

use_math: true
published: true
---

<br>

이번 내용에는 Text Analytics Toolbox™ Model for fastText English 16 Billion Token Word Embedding 패키지 설치가 필요하다.

***

### 1.4.1 Word Embedding

<br>

사전에 훈련된 word embedding을 `fastTextWordEmbedding`을 사용해 불러온다.

```
emb = fastTextWordEmbedding
```

<p align="center"><img src="/assets/image/matlab/text/1.11.png" width="70%" height="70%" title="" alt=""><br/></p>

Word embedding이란 단어를 숫자 혹은 벡터로 표현하는 것. 이렇게 하면 단어끼리의 관계를 숫자로 표현할 수 있고 단어 사이의 연산도 가능하게 된다.

`word2vec`을 사용해 단어를 벡터에 mapping하자.

<br>

```
% 단어를 embedding
italy = word2vec(emb, 'Italy')
rome = word2vec(emb, 'Rome')
paris = word2vec(emb, 'Paris')
```

<p align="center"><img src="/assets/image/matlab/text/1.12.png" width="70%" height="70%" title="" alt=""><br/></p>

<br>

이제 다음과 같은 질문을 생각하자.

$$
\textrm{Italy - Rome + Paris = ?}
$$

```
word = vec2word(emb, italy - rome + paris)

---
word = "France"

```

<p align="center"><img src="/assets/image/matlab/text/1.13.png" width="70%" height="70%" title="" alt=""><br/></p>