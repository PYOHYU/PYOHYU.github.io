---
title:  "1.2 Multivariable Linear Regression"
excerpt: 

categories:
  - Robot
tags:
  - [Machine Learning]

toc: true
toc_sticky: true
 
date: 2022-07-05
last_modified_at: 2022-07-05

use_math: true
published: true
---

<br>

영훈이는 오늘도 또 싱글벙글 게임을 켰다. 어제는 슬라임만 잡았지만 오늘은 다르다. 슬라임을 17마리, 고블린을 25마리, 늑대를 10마리 잡았더니 1695원을 벌었다. 

|Slime ($x_1$)|Goblin ($x_2$)|Wolf ($x_3$)|Money ($y$)|
|---|---|---|---|
|17|25|10|1985|
|36|7|31|3185|
|22|23|47|4285|
|5|21|11|1545|
|45|17|41|4405|

슬라임을 $x_1$마리, 고블린을 $x_2$마리, 늑대를 $x_3$마리 사냥했을 때 얼마를 벌 수 있는지 예측하고 싶다.

<script src="https://gist.github.com/PYOHYU/cd532dc35baf2de9019a47e4d883b206.js"></script>

<br>

***

### Example 1.1.2

Hypothesis function이 다음과 같았던 것을 기억하자.

$$H(x) = Wx + b$$

따라서, 입력 변수가 3개이면 weight도 3개의 성분으로 이루어져 있어야 한다.

$$H(x) = w_1x_1 + w_2x_2 + w_3x_3 + b$$

만약 입력 변수가 1000개이면...

<br>

`matmul()` 함수는 두 array의 matrix product를 계산한다. 훨씬 간결하며 입력 변수의 개수가 바뀌어도 코드를 바꿀 필요가 없어진다.

이번에도 cost 함수는 MSE를 사용하자. 기존의 simple linear regression과 동일한 방식이다.

$$ cost(W, b) = \frac{1}{m} \sum_{i=1}^m (H(x^{(i)}) - y^{(i)})^2$$

<script src="https://gist.github.com/PYOHYU/b00a8a1a237856f16b72923d3d6426e4.js"></script>

```cpp
 - Result : 
  Epoch  100/1000 hypothesis: tensor([2016.3593, 3206.3818, 4227.2891, 1537.0814, 4428.6533]), W: tensor([32.8706, 35.3919, 57.2540]), b: 0.0000, Cost: 1078.664307
  Epoch  200/1000 hypothesis: tensor([1996.3647, 3188.8352, 4270.0488, 1545.6074, 4410.2295]), W: tensor([30.7304, 35.2673, 59.2133]), b: 0.0000, Cost: 79.024063
  Epoch  300/1000 hypothesis: tensor([1988.3540, 3185.9561, 4280.8555, 1545.3354, 4406.3931]), W: tensor([30.2016, 35.0845, 59.7772]), b: 0.0000, Cost: 6.278736
  Epoch  400/1000 hypothesis: tensor([1985.9556, 3185.2627, 4283.8340, 1545.1041, 4405.3887]), W: tensor([30.0567, 35.0244, 59.9370]), b: 0.0000, Cost: 0.500723
  Epoch  500/1000 hypothesis: tensor([1985.2705, 3185.0737, 4284.6709, 1545.0300, 4405.1094]), W: tensor([30.0160, 35.0069, 59.9822]), b: 0.0000, Cost: 0.039957
  Epoch  600/1000 hypothesis: tensor([1985.0764, 3185.0210, 4284.9067, 1545.0085, 4405.0308]), W: tensor([30.0045, 35.0020, 59.9950]), b: 0.0000, Cost: 0.003199
  Epoch  700/1000 hypothesis: tensor([1985.0217, 3185.0059, 4284.9736, 1545.0026, 4405.0088]), W: tensor([30.0013, 35.0006, 59.9986]), b: 0.0000, Cost: 0.000257
  Epoch  800/1000 hypothesis: tensor([1985.0059, 3185.0017, 4284.9922, 1545.0005, 4405.0024]), W: tensor([30.0004, 35.0002, 59.9996]), b: 0.0000, Cost: 0.000021
  Epoch  900/1000 hypothesis: tensor([1985.0024, 3185.0000, 4284.9980, 1545.0006, 4405.0005]), W: tensor([30.0001, 35.0001, 59.9999]), b: 0.0000, Cost: 0.000002
  Epoch 1000/1000 hypothesis: tensor([1985.0024, 3185.0000, 4284.9980, 1545.0006, 4405.0005]), W: tensor([30.0001, 35.0001, 59.9999]), b: 0.0000, Cost: 0.000002
```

epoch가 진행될수록 cost는 점점 작아지고, $H(x)$는 $y$에 가까워지는 것을 알 수 있다.

***

<br>
